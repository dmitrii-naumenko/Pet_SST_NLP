{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import io\n",
    "import os\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('../data/valid.csv')\n",
    "df_train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yandex Cloud STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brew install ffmpeg\n",
    "\n",
    "import sys\n",
    "sys.path.append('/path/to/ffmpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../secrets/yandex-traslate-apikey.txt', 'r') as file:\n",
    "    apikey = file.read().replace('\\n', '')\n",
    "    \n",
    "def yandex_stt(filename: str, lang:str = 'ru-RU', sampleRateHertz: int = 8000) -> str:\n",
    "\n",
    "    fn = f'../data/speech/{filename}'\n",
    "    if os.path.getsize(fn) < 500:\n",
    "        return ''\n",
    "    \n",
    "    url = f\"https://stt.api.cloud.yandex.net/speech/v1/stt:recognize?lang={lang}&format=lpcm&sampleRateHertz={sampleRateHertz}\"\n",
    "\n",
    "    sound = AudioSegment.from_mp3(fn)\n",
    "    sound = sound.set_frame_rate(sampleRateHertz)\n",
    "    buffer = io.BytesIO()\n",
    "    sound.export(buffer, format='wav')\n",
    "    files = {'file': buffer.read()[:1_000_000]}\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Api-Key {apikey}',\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, files=files)\n",
    "    return response.json()['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:50<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def apply_fn(speech_fn):\n",
    "    return yandex_stt(speech_fn)\n",
    "\n",
    "df_valid['yandex_tts'] = df_valid['speech_fn'].progress_apply(apply_fn)\n",
    "df_valid.to_csv('../data/yandex_stt_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6407131801825868"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.apply(lambda row: sentence_bleu([row['text_ru']],row['yandex_tts']), axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOSK\n",
    "\n",
    "модели можно скачать тут (содержимое распаковать в соотвествующую папку)\n",
    "https://alphacephei.com/vosk/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vosk_stt(model, filename: str) -> str:\n",
    "\n",
    "    fn = f'../data/speech/{filename}'\n",
    "    if os.path.getsize(fn) < 500:\n",
    "        return ''\n",
    "    \n",
    "\n",
    "    sound = AudioSegment.from_mp3(fn)\n",
    "    rec.AcceptWaveform(sound.raw_data)\n",
    "    result = rec.Result()\n",
    "    text = json.loads(result)[\"text\"]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small russian vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ../vosk-model-small-ru-0.22//ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from ../vosk-model-small-ru-0.22//graph/HCLr.fst ../vosk-model-small-ru-0.22//graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo ../vosk-model-small-ru-0.22//graph/phones/word_boundary.int\n",
      "100%|██████████| 200/200 [01:06<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "model = Model(\"../vosk-model-small-ru-0.22/\")\n",
    "rec = KaldiRecognizer(model, 48000)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def apply_fn(speech_fn):\n",
    "    return vosk_stt(model, speech_fn)\n",
    "\n",
    "df_valid['vosksmall_tts'] = df_valid['speech_fn'].progress_apply(apply_fn)\n",
    "df_valid.to_csv('../data/vosksmall_stt_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5767803833812252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.apply(lambda row: sentence_bleu([row['text_ru']],row['vosksmall_tts']), axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large russian vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
      "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ../vosk-model-ru-0.42//ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from ../vosk-model-ru-0.42//graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from ../vosk-model-ru-0.42//graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo ../vosk-model-ru-0.42//graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from ../vosk-model-ru-0.42//rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from ../vosk-model-ru-0.42//rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from ../vosk-model-ru-0.42//rnnlm/final.raw\n",
      "100%|██████████| 200/200 [03:06<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "model = Model(\"../vosk-model-ru-0.42/\")\n",
    "rec = KaldiRecognizer(model, 48000)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def apply_fn(speech_fn):\n",
    "    return vosk_stt(model, speech_fn)\n",
    "\n",
    "df_valid['vosk_tts'] = df_valid['speech_fn'].progress_apply(apply_fn)\n",
    "df_valid.to_csv('../data/vosks_stt_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/dima/Repo/Pet_SST_NLP/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49000397511625976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.apply(lambda row: sentence_bleu([row['text_ru']],row['vosk_tts']), axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем файл текста для трейна (на всякий случай)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ../vosk-model-small-ru-0.22//ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from ../vosk-model-small-ru-0.22//graph/HCLr.fst ../vosk-model-small-ru-0.22//graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo ../vosk-model-small-ru-0.22//graph/phones/word_boundary.int\n",
      "100%|██████████| 600/600 [03:39<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "model = Model(\"../vosk-model-small-ru-0.22/\")\n",
    "rec = KaldiRecognizer(model, 48000)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def apply_fn(speech_fn):\n",
    "    return vosk_stt(model, speech_fn)\n",
    "\n",
    "df_train['vosksmall_tts'] = df_train['speech_fn'].progress_apply(apply_fn)\n",
    "df_train.to_csv('../data/vosksmall_stt_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "- 0.64 - Yandex SpeechKit (online) - базовое значение очень хорошей модели\n",
    "- **0.57** - Vosk RU Small (offline) - хороший результат\n",
    "- 0.49 - Vosk RU Large (offline) - больше не значит лучше, хотя может быть вызвано грязными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
